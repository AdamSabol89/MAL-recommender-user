{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from malscraper import users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the webpage\n",
    "r = requests.get(\"https://myanimelist.net/users.php\")\n",
    "\n",
    "#beautiful soup object\n",
    "soup = bs(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get table \n",
    "table = soup.find(\"table\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get user info\n",
    "usersdiv = table.find_all(\"div\", attrs={\"style\":\"margin-bottom: 7px;\"})\n",
    "usersdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "for i in range(len(usersdiv)):\n",
    "    print(usersdiv[i].a[\"href\"]+ ' ' + usersdiv[i].get_text())\n",
    "    users.append(usersdiv[i].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://myanimelist.net/animelist/Pranimetikee\"\n",
    "soup2 = bs(requests.get(url).text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads( soup2.select_one('.list-table[data-items]')['data-items'] )   # load data from `data-items` attribute\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "prant = requests.get(url)\n",
    "resp = prant.json()\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(times, delay=2):\n",
    "    final_data = pd.DataFrame()\n",
    "   \n",
    "    for index in range(times):\n",
    "        r = requests.get(\"https://myanimelist.net/users.php\")\n",
    "        time.sleep(.5)\n",
    "        soup = bs(r.content)\n",
    "        table = soup.find(\"table\")\n",
    "        usersdiv = table.find_all(\"div\", attrs={\"style\":\"margin-bottom: 7px;\"})\n",
    "        malusers = []\n",
    "        \n",
    "        for i in range(len(usersdiv)):\n",
    "            malusers.append(usersdiv[i].get_text())\n",
    "        print(malusers)\n",
    "        for maluser in malusers:\n",
    "            try:\n",
    "                data = users.get_user_anime_list(maluser)\n",
    "                df= pd.DataFrame(data)\n",
    "                final_data = final_data.append(df)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "\n",
    "    return final_data\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = scraper(220)\n",
    "anime_data2 = scraper(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_data = anime_data.append(anime_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_data.to_csv(\"AnimeData\", header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
